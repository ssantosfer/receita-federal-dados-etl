# Receita Federal ETL

Este projeto implementa um pipeline de ingest√£o e transforma√ß√£o de dados p√∫blicos disponibilizados pela Receita Federal sobre **Empresas** e **S√≥cios**.  

---

## Objetivo do Desafio

- Ingest√£o de dados p√∫blicos (empresas e s√≥cios) a partir de arquivos disponibilizados pela Receita Federal.
- Processamento e padroniza√ß√£o dos dados em m√∫ltiplas camadas de transforma√ß√£o.
- Gera√ß√£o de uma tabela final com atributos enriquecidos:
  - `cnpj`
  - `qtde_socios`
  - `flag_socio_estrangeiro`
  - `doc_alvo`

---

## Arquitetura em Camadas

O projeto segue a arquitetura em camadas conhecida como **Medallion Architecture**:

### 1. Bronze (Raw Layer)
- **O que √©:**  
  Camada de ingest√£o **bruta** dos dados diretamente do endpoint da Receita Federal (arquivos `.zip`).
- **Objetivo:**  
  Preservar a integridade dos dados originais, sem tratamentos, garantindo reprocessamento se necess√°rio.
- **Exemplo:**  
  Arquivos extra√≠dos em `data/bronze/empresas` e `data/bronze/socios`.

---

### 2. Silver (Curated Layer)
- **O que √©:**  
  Camada de **tratamento e padroniza√ß√£o**, onde os dados brutos s√£o limpos, colunas s√£o renomeadas, e tipos de dados s√£o ajustados.
- **Objetivo:**  
  Garantir dados estruturados, consistentes e prontos para an√°lises ou integra√ß√µes.
- **Exemplo de tabelas criadas:**
```sql  
  - `stg_empresas`  
  - `stg_socios`
```
---

### 3. Gold (Business Layer)
- **O que √©:**  
  Camada de **modelagem anal√≠tica**, onde regras de neg√≥cio s√£o aplicadas e m√©tricas/indicadores s√£o criados.
- **Objetivo:**  
  Disponibilizar dados prontos para consumo por aplica√ß√µes transacionais e anal√≠ticas.
- **Exemplo de tabela criada:**  
  - `agg_empresas` com:
    - `cnpj`
    - `qtde_socios`
    - `flag_socio_estrangeiro`
    - `doc_alvo`

---

## Tecnologias Utilizadas

- **Python 3.12**
- **Pandas** para manipula√ß√£o de dados
- **SQLAlchemy** + **Postgres** para persist√™ncia
- **Docker & Docker Compose** para containeriza√ß√£o
- **Logging** para rastreabilidade e monitoramento do pipeline

---

## Como Executar

### 1. Clonar o reposit√≥rio
```bash
git clone https://github.com/ssantosfer/receita-federal-dados-etl.git
cd receita-federal-dados-etl
```

### 2. Configurar vari√°veis de ambiente
Crie um arquivo .env baseado no exemplo:
``` .env
POSTGRES_USER=etl_user
POSTGRES_PASSWORD=etl_pass
POSTGRES_DB=etl_db
POSTGRES_PORT=5432
POSTGRES_CONN=postgresql+psycopg2://etl_user:etl_pass@db:5432/etl_db
```
### 3. Subir os containers
```bash
docker-compose up --build
```
### 4. Executar o pipeline
O container pipeline j√° executa automaticamente o main.py.
Ao final, os dados estar√£o dispon√≠veis nas tabelas:

`stg_empresas`  
`stg_socios`
`agg_empresas`

---

## üöÄ Executando o projeto sem Docker

O processo tamb√©m pode ser executado **sem a utiliza√ß√£o do Docker**.  
Para isso, siga os passos abaixo:

1. Crie um arquivo `.env` na raiz do projeto com a vari√°vel de conex√£o completa:

   ```bash
   POSTGRES_CONN=postgresql+psycopg2://<usuario>:<senha>@localhost:5432/<nome_do_banco>
  ```
Substitua <usuario>, <senha> e <nome_do_banco> pelos valores corretos do seu PostgreSQL local.

2. Execute o pipeline diretamente com Python:
   ```bash
    python main.py
  ```
---

## Estrutura do Projeto
```bash
‚îú‚îÄ‚îÄ data/               # Dados armazenados em camadas (bronze, silver,gold)
‚îú‚îÄ‚îÄ extract/            # Scripts de ingest√£o (download e extra√ß√£o)
‚îú‚îÄ‚îÄ transform/          # Scripts de tratamento (camada silver)
‚îú‚îÄ‚îÄ load/               # Scripts de persist√™ncia no banco (camada gold)
‚îú‚îÄ‚îÄ utils/              # Fun√ß√µes utilit√°rias
‚îú‚îÄ‚îÄ schema/             # Esquema das tabelas que est√£o sendo ingeridas
‚îú‚îÄ‚îÄ main.py             # Orquestra√ß√£o do pipeline
‚îú‚îÄ‚îÄ requirements.txt    # Depend√™ncias do projeto
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ docker-compose.yml
‚îî‚îÄ‚îÄ README.md
```
### Dados Locais

Os arquivos de dados (bronze, silver, gold) n√£o s√£o versionados no GitHub para manter o reposit√≥rio leve, devido ao volume de dados.
Eles s√£o ignorados via .gitignore.
Ao rodar o pipeline (main.py), os dados s√£o automaticamente baixados e processados nas respectivas camadas.

![alt text](dados_locais.png)

---

## Output Final

Tabela `agg_empresas`:

| Coluna                   | Tipo    | Descri√ß√£o                                                                 |
| ------------------------ | ------- | ------------------------------------------------------------------------- |
| `cnpj`                   | string  | N√∫mero de inscri√ß√£o no CNPJ                                               |
| `qtde_socios`            | int     | N√∫mero total de s√≥cios participantes                                      |
| `flag_socio_estrangeiro` | boolean | True se existe pelo menos 1 s√≥cio estrangeiro                             |
| `doc_alvo`               | boolean | True se porte da empresa = 03 **e** possui mais de 1 s√≥cio; caso contr√°rio, False |

![alt text](agg_empresas.png)